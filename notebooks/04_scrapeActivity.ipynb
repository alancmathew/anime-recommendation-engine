{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e41c1a6c-3f8c-4d85-b3d5-cd9f6bf18dcb",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Scrape User Activity List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1231f4b-f867-4983-83e5-201b954bcd14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def scrapeTable(url, attempt=1):\n",
    "#     if attempt == 4:\n",
    "#         return pd.DataFrame(columns=['title', 'type', 'year', 'avg', 'status', \n",
    "#                                      'eps', 'times_watched', 'rating'])\n",
    "    \n",
    "#     resp = requests.get(f'http://192.168.0.3:5000/special-requests?url={quote(url)}')\n",
    "#     if resp.text != '':\n",
    "#         try:\n",
    "#             soup = BeautifulSoup(resp.text, 'html.parser')\n",
    "#             table = soup.find('table')\n",
    "#             chunk = pd.read_html(StringIO(str(table)))[0]\n",
    "#             chunk.columns = ['title', 'type', 'year', 'avg', 'status', 'eps', 'times_watched', 'rating']\n",
    "#             chunk['url'] = [np.where(tag.has_attr('href'), \n",
    "#                                'https://www.anime-planet.com' + tag.get('href'), \n",
    "#                                'no link') for tag in [td.find('a') for td in table.find_all('td', attrs={'class':'tableTitle'})]]\n",
    "#             chunk['url'] = chunk['url'].astype('string')\n",
    "#             return chunk\n",
    "#         except:\n",
    "#             return scrapeTable(url, attempt+1)\n",
    "#     else:\n",
    "#         return scrapeTable(url, attempt+1)\n",
    "\n",
    "# def scrapeUserWatched(username, attempt=1):\n",
    "#     if attempt == 4:\n",
    "#         return pd.DataFrame(columns=['title', 'type', 'year', 'avg', 'status', \n",
    "#                                      'eps', 'times_watched', 'rating', 'username'])\n",
    "    \n",
    "#     url = f'https://www.anime-planet.com/users/{username}/anime/watched?sort=title&mylist_view=list'\n",
    "#     resp = requests.get(f'http://192.168.0.3:5000/special-requests?url={quote(url)}')\n",
    "#     if resp.text != '':\n",
    "#         try:\n",
    "#             soup = BeautifulSoup(resp.text, 'html.parser')\n",
    "#             ul = soup.find('ul', attrs={'class':'nav'})\n",
    "#             page_nums = []\n",
    "#             for tag in ul.find_all('a'):\n",
    "#                 try:\n",
    "#                     page_nums.append(int(tag.text))\n",
    "#                 except:\n",
    "#                     continue\n",
    "#             num_pages = max(page_nums)\n",
    "\n",
    "#             urls = [f'{url}&page={i}' for i in range(1, num_pages+1)]\n",
    "\n",
    "#             with ThreadPoolExecutor(max_workers=10) as executor:\n",
    "#                 df_list = list(executor.map(scrapeTable, urls))\n",
    "\n",
    "#             df = pd.concat(df_list)\n",
    "\n",
    "#             df['username'] = username\n",
    "            \n",
    "#             with db.connect() as con:\n",
    "#                 df.to_sql('user', con, index=False, if_exists='append', method='multi')\n",
    "            \n",
    "#         except:\n",
    "#             scrapeUserWatched(username, attempt+1)\n",
    "        \n",
    "#     else:\n",
    "#         scrapeUserWatched(username, attempt+1)\n",
    "\n",
    "# for username in tqdm(usernames):\n",
    "#     scrapeUserWatched(username)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9c585c9-2335-47d7-9c06-13340d44bb99",
   "metadata": {},
   "outputs": [],
   "source": [
    "url_html_df = pd.DataFrame(columns=['url','html_text'])\n",
    "pending = set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b65e0be-e5eb-436d-9ae1-664753180292",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getUserFirstPage(username, attempt=1):\n",
    "    if attempt == 4:\n",
    "        return (url, '')\n",
    "    \n",
    "    try:\n",
    "        url = f'https://www.anime-planet.com/users/{username}/anime?sort=title&mylist_view=list'\n",
    "        resp = requests.get(f'http://192.168.0.3:5000/special-requests?url={quote(url)}')\n",
    "        if resp.text != '':\n",
    "            return (url, resp.text)\n",
    "        \n",
    "        else:\n",
    "            return getUserFirstPage(username, attempt+1)\n",
    "            \n",
    "    except:\n",
    "        return getUserFirstPage(username, attempt+1)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea779b4-b7ef-4d47-8df6-4fa656100a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def addAdditionalPages(html_text):\n",
    "    soup = BeautifulSoup(html_text, 'html.parser')\n",
    "    ul = soup.find('ul', attrs={'class':'nav'})\n",
    "    page_nums = []\n",
    "    for tag in ul.find_all('a'):\n",
    "        try:\n",
    "            page_nums.append(int(tag.text))\n",
    "        except:\n",
    "            continue\n",
    "    num_pages = max(page_nums)\n",
    "\n",
    "    urls = [f'{url}&page={i}' for i in range(1, num_pages+1)]\n",
    "    \n",
    "    pending.update(urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f24a3737-7c81-431a-ad7f-8da1fdfa40ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunksize = 10\n",
    "\n",
    "username_chunks = chunker(usernames, chunksize)\n",
    "\n",
    "for idx, username_chunk in enumerate(tqdm(username_chunks, total=len(usernames)/chunksize)):\n",
    "    with ThreadPoolExecutor(max_workers=10) as executor:\n",
    "        list_of_tups = list(executor.map(getUserFirstPage, username_chunk))\n",
    "        url_html_df = pd.concat([url_html_df, \n",
    "                                 pd.DataFrame(list_of_tups, columns=['url','html_text'])], \n",
    "                                ignore_index=True)\n",
    "    if idx % 10 == 0:\n",
    "        \n",
    "    time.sleep(random.randint(2, 5))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
