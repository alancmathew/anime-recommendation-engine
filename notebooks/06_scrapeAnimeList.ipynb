{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6576d1a9-c7b7-44fa-9e3a-3c5f2ffffef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import sqlalchemy as sql\n",
    "from sqlalchemy import create_engine\n",
    "from tqdm import tqdm\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from io import StringIO \n",
    "import time\n",
    "import re\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from multiprocessing import Pool\n",
    "import random\n",
    "from urllib.parse import quote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9fcffb7f-c0cd-4616-a12d-eec102ac08f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../tools/credentials.json') as file:\n",
    "    credentials = json.load(file)\n",
    "    \n",
    "username = credentials[\"dblogin\"][\"username\"]\n",
    "password = credentials[\"dblogin\"][\"password\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "20b6a4ed-3c8a-4eec-a5c7-f36b25b78f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "db_string = f\"postgresql://{username}:{password}@192.168.0.3:5432/animeplanet\"\n",
    "db = create_engine(db_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1e5d0c56-40fd-453c-b7d1-6815127c0088",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunker(seq, size):\n",
    "    return (seq[pos:pos + size] for pos in range(0, len(seq), size))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceff2d96-0e42-41b8-9080-b7ac20d62851",
   "metadata": {},
   "source": [
    "### Get Anime List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eee1d902-3ec1-48fc-98a2-9dad3d4abd4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('scraping anime list...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b272b19-78fd-4598-aea4-9da726bc8418",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url = 'https://www.anime-planet.com/anime/top-anime?page='\n",
    "\n",
    "url = f'{base_url}{1}'\n",
    "resp = requests.get(f'http://192.168.0.3:5000/special-requests?url={quote(url)}')\n",
    "soup = BeautifulSoup(resp.text, 'html.parser')\n",
    "ul = soup.find('ul', attrs={'class':'nav'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be3f6a78-5cf8-4b1d-8b51-3d516b89fc45",
   "metadata": {},
   "outputs": [],
   "source": [
    "page_nums = []\n",
    "for tag in ul.find_all('a'):\n",
    "    try:\n",
    "        page_nums.append(int(tag.text))\n",
    "    except:\n",
    "        continue\n",
    "        \n",
    "num_pages = max(page_nums)\n",
    "\n",
    "urls = [f'{base_url}{i}' for i in range(1, num_pages+1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60669125-bfc7-4b43-ac97-f430b18811d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrapeTable(url):\n",
    "    resp = requests.get(f'http://192.168.0.3:5000/special-requests?url={quote(url)}')\n",
    "    if resp.text != '':\n",
    "        soup = BeautifulSoup(resp.text, 'html.parser')\n",
    "        table = soup.find('table')\n",
    "        chunk = pd.read_html(StringIO(str(table)), index_col='Rank')[0][['Title', 'Type', 'Year']]\n",
    "        chunk['url'] = [np.where(tag.has_attr('href'), \n",
    "                           'https://www.anime-planet.com' + tag.get('href'), \n",
    "                           'no link') for tag in table.find_all('a')]\n",
    "        chunk.columns = [col.lower() for col in chunk.columns]\n",
    "        chunk['url'] = chunk['url'].astype('string')\n",
    "        return chunk\n",
    "    else:\n",
    "        return scrapeTable(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0c9654f-4c50-422e-8519-6127aff23cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunksize = 10\n",
    "df = pd.DataFrame()\n",
    "\n",
    "url_chunks = chunker(urls, chunksize)\n",
    "\n",
    "for idx, url_chunk in enumerate(tqdm(url_chunks, total=int(len(urls)/chunksize)+1), 1):\n",
    "    with ThreadPoolExecutor(max_workers=chunksize) as executor:\n",
    "        chunk = pd.concat(list(executor.map(scrapeTable, url_chunk)), ignore_index=True)\n",
    "        \n",
    "    df = pd.concat([df, chunk], ignore_index=True)\n",
    " \n",
    "    time.sleep(max(min(np.random.poisson(2), 5), 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d016263c-e1c0-4981-a29a-cabd2ad8a926",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop_duplicates(['url'], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa07b4fb-c1d2-49e1-b9c9-7f877712c5c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('saving data to file...')\n",
    "df.to_csv('../data/anime_list.csv.xz', index=False)\n",
    "\n",
    "with db.connect() as con:\n",
    "    print('removing from db...')\n",
    "    query = f\"\"\"DELETE FROM anime;\"\"\"\n",
    "    con.execute(sql.text(query))\n",
    "    \n",
    "    print('saving data to db...')\n",
    "    df.to_sql('anime', con, if_exists='append', index=False, method='multi')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59626afb-45a2-418e-bd16-4663d7b114fa",
   "metadata": {},
   "source": [
    "### Scrape Anime Pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be649d16-86de-46b4-a555-6c2310730822",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('scraping anime pages...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53cfecbf-f385-4dc1-ae84-80a6f8d18727",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_sql('anime', db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76680e11-4d46-4748-aafd-11118cab84d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPage(url, attempt=1):\n",
    "    if attempt == 4:\n",
    "        return (url, '')\n",
    "    resp = requests.get(f'http://192.168.0.3:5000/special-requests?url={quote(url)}')\n",
    "    return (url, resp.text) if resp.text != '' else getPage(url, attempt+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02192b75-8043-4308-abd2-d427c61431d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunksize = 10\n",
    "\n",
    "url_list = df['url'].to_list()\n",
    "url_chunks = chunker(url_list, chunksize)\n",
    "\n",
    "url_html_dict = {}\n",
    "for url_chunk in tqdm(url_chunks, total=int(len(url_list)/chunksize)+1):\n",
    "    with ThreadPoolExecutor(max_workers=chunksize) as executor:\n",
    "        list_of_tup = list(executor.map(getPage, url_chunk))\n",
    "        for tup in list_of_tup:\n",
    "            url_html_dict[tup[0]] = tup[1]\n",
    "            \n",
    "    time.sleep(max(min(np.random.poisson(10), 30), 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ef9f432-321a-4759-9918-a3873dd5560a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['html_text'] = df['url'].map(url_html_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6f2a860-7473-4e0f-8b59-527dcf1241f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('saving data to file...')\n",
    "df.to_csv('../data/anime_list_html.csv.xz', index=False)\n",
    "\n",
    "with db.connect() as con:\n",
    "    print('removing from db...')\n",
    "    query = f\"\"\"DELETE FROM web_scrape \n",
    "                WHERE url in ({str(df['url'].to_list())[1:-1]})\"\"\"\n",
    "    con.execute(sql.text(query))\n",
    "    print('saving data to db...')\n",
    "    chunks = chunker(df[['url', 'html_text']], 1000)\n",
    "    for chunk in tqdm(chunks):\n",
    "        chunk.to_sql('web_scrape', con, if_exists='append', index=False, method='multi')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eadea1ee-dc7b-424c-9c5b-2ff01c222784",
   "metadata": {},
   "source": [
    "### Extracting addition info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "34734c37-df02-4051-81bd-5b6d85f6e399",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/anime_list_html.csv.xz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2165e754-720a-47ce-a5df-56fd50c7c7e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>type</th>\n",
       "      <th>year</th>\n",
       "      <th>url</th>\n",
       "      <th>html_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Gag Manga Biyori 2</td>\n",
       "      <td>TV</td>\n",
       "      <td>2006.0</td>\n",
       "      <td>https://www.anime-planet.com/anime/gag-manga-b...</td>\n",
       "      <td>\\n&lt;!doctype html&gt;\\n&lt;html xml:lang=\"en\" lang=\"e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Fu Yu Nu</td>\n",
       "      <td>Movie</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>https://www.anime-planet.com/anime/fu-yu-nu</td>\n",
       "      <td>\\n&lt;!doctype html&gt;\\n&lt;html xml:lang=\"en\" lang=\"e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Kijeu CSI: Gwahaksusadae</td>\n",
       "      <td>TV</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>https://www.anime-planet.com/anime/kijeu-csi-g...</td>\n",
       "      <td>\\n&lt;!doctype html&gt;\\n&lt;html xml:lang=\"en\" lang=\"e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Zuoshou Shanglan</td>\n",
       "      <td>Web</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.anime-planet.com/anime/zuoshou-sha...</td>\n",
       "      <td>\\n&lt;!doctype html&gt;\\n&lt;html xml:lang=\"en\" lang=\"e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Jeonsa Ryan</td>\n",
       "      <td>Movie</td>\n",
       "      <td>1997.0</td>\n",
       "      <td>https://www.anime-planet.com/anime/jeonsa-ryan</td>\n",
       "      <td>\\n&lt;!doctype html&gt;\\n&lt;html xml:lang=\"en\" lang=\"e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17122</th>\n",
       "      <td>BanG Dream! Movie: Episode of Roselia - Part I...</td>\n",
       "      <td>Movie</td>\n",
       "      <td>2021.0</td>\n",
       "      <td>https://www.anime-planet.com/anime/bang-dream-...</td>\n",
       "      <td>\\n&lt;!doctype html&gt;\\n&lt;html xml:lang=\"en\" lang=\"e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17123</th>\n",
       "      <td>Yu Yu Hakusho Picture Drama</td>\n",
       "      <td>DVD Special</td>\n",
       "      <td>2009.0</td>\n",
       "      <td>https://www.anime-planet.com/anime/yu-yu-hakus...</td>\n",
       "      <td>\\n&lt;!doctype html&gt;\\n&lt;html xml:lang=\"en\" lang=\"e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17124</th>\n",
       "      <td>Kannagi: If You Are a Shrine Maiden</td>\n",
       "      <td>DVD Special</td>\n",
       "      <td>2009.0</td>\n",
       "      <td>https://www.anime-planet.com/anime/kannagi-if-...</td>\n",
       "      <td>\\n&lt;!doctype html&gt;\\n&lt;html xml:lang=\"en\" lang=\"e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17125</th>\n",
       "      <td>KADO: The Right Answer</td>\n",
       "      <td>TV</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>https://www.anime-planet.com/anime/kado-the-ri...</td>\n",
       "      <td>\\n&lt;!doctype html&gt;\\n&lt;html xml:lang=\"en\" lang=\"e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17126</th>\n",
       "      <td>Yusei High School Astronomy Club</td>\n",
       "      <td>Web</td>\n",
       "      <td>2021.0</td>\n",
       "      <td>https://www.anime-planet.com/anime/yusei-high-...</td>\n",
       "      <td>\\n&lt;!doctype html&gt;\\n&lt;html xml:lang=\"en\" lang=\"e...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17127 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   title         type    year  \\\n",
       "0                                     Gag Manga Biyori 2           TV  2006.0   \n",
       "1                                               Fu Yu Nu        Movie  2016.0   \n",
       "2                               Kijeu CSI: Gwahaksusadae           TV  2012.0   \n",
       "3                                       Zuoshou Shanglan          Web     NaN   \n",
       "4                                            Jeonsa Ryan        Movie  1997.0   \n",
       "...                                                  ...          ...     ...   \n",
       "17122  BanG Dream! Movie: Episode of Roselia - Part I...        Movie  2021.0   \n",
       "17123                        Yu Yu Hakusho Picture Drama  DVD Special  2009.0   \n",
       "17124                Kannagi: If You Are a Shrine Maiden  DVD Special  2009.0   \n",
       "17125                             KADO: The Right Answer           TV  2017.0   \n",
       "17126                   Yusei High School Astronomy Club          Web  2021.0   \n",
       "\n",
       "                                                     url  \\\n",
       "0      https://www.anime-planet.com/anime/gag-manga-b...   \n",
       "1            https://www.anime-planet.com/anime/fu-yu-nu   \n",
       "2      https://www.anime-planet.com/anime/kijeu-csi-g...   \n",
       "3      https://www.anime-planet.com/anime/zuoshou-sha...   \n",
       "4         https://www.anime-planet.com/anime/jeonsa-ryan   \n",
       "...                                                  ...   \n",
       "17122  https://www.anime-planet.com/anime/bang-dream-...   \n",
       "17123  https://www.anime-planet.com/anime/yu-yu-hakus...   \n",
       "17124  https://www.anime-planet.com/anime/kannagi-if-...   \n",
       "17125  https://www.anime-planet.com/anime/kado-the-ri...   \n",
       "17126  https://www.anime-planet.com/anime/yusei-high-...   \n",
       "\n",
       "                                               html_text  \n",
       "0      \\n<!doctype html>\\n<html xml:lang=\"en\" lang=\"e...  \n",
       "1      \\n<!doctype html>\\n<html xml:lang=\"en\" lang=\"e...  \n",
       "2      \\n<!doctype html>\\n<html xml:lang=\"en\" lang=\"e...  \n",
       "3      \\n<!doctype html>\\n<html xml:lang=\"en\" lang=\"e...  \n",
       "4      \\n<!doctype html>\\n<html xml:lang=\"en\" lang=\"e...  \n",
       "...                                                  ...  \n",
       "17122  \\n<!doctype html>\\n<html xml:lang=\"en\" lang=\"e...  \n",
       "17123  \\n<!doctype html>\\n<html xml:lang=\"en\" lang=\"e...  \n",
       "17124  \\n<!doctype html>\\n<html xml:lang=\"en\" lang=\"e...  \n",
       "17125  \\n<!doctype html>\\n<html xml:lang=\"en\" lang=\"e...  \n",
       "17126  \\n<!doctype html>\\n<html xml:lang=\"en\" lang=\"e...  \n",
       "\n",
       "[17127 rows x 5 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cce94f32-1b04-46df-8e03-62ebe443ca81",
   "metadata": {},
   "outputs": [],
   "source": [
    "def email(string):\n",
    "    r = int(string[:2], 16)\n",
    "    email = ''.join([chr(int(string[i:i+2], 16) ^ r)\n",
    "                     for i in range(2, len(string), 2)])\n",
    "    return email"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7c84db51-30ac-4a72-9ff5-c168834f906c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parseInfo(html):\n",
    "    soup = BeautifulSoup(html)\n",
    "    title = soup.find('h1', {'itemprop':'name'}).text\n",
    "    if '[email\\xa0protected]' in title:\n",
    "        real_text = email(soup.find('a', attrs={'href': '/cdn-cgi/l/email-protection'})['data-cfemail'])\n",
    "        title = title.replace('[email\\xa0protected]', real_text)\n",
    "\n",
    "    section = soup.find(attrs={'class': 'pure-g entryBar'})\n",
    "    num_eps = section.find('span', {'class':'type'})\n",
    "    if num_eps:\n",
    "        num_eps = num_eps.text.replace('\\n', ' ').strip()\n",
    "    else:\n",
    "        num_eps = None\n",
    "    \n",
    "    studio = section.find('a', {'href': re.compile(r'/anime/studios/.*')})\n",
    "    if studio:\n",
    "        studio = studio.text\n",
    "    else:\n",
    "        studio = None\n",
    "    \n",
    "    start_end_years = section.find('span', {'class': 'iconYear'})\n",
    "    if start_end_years:\n",
    "        start_end_years = start_end_years.text\n",
    "    else:\n",
    "        start_end_years = None\n",
    "    \n",
    "    season_year = section.find('a', {'href': re.compile(r'/anime/seasons/.*')})\n",
    "    if season_year:\n",
    "        season_year = season_year.text\n",
    "    else:\n",
    "        season_year = None\n",
    "        \n",
    "    rating = section.find('div', {'class': 'avgRating'}).text.replace('\\n', ' ').strip()\n",
    "    \n",
    "    tags_section = soup.find('div', {'class':'tags'})\n",
    "    if tags_section:\n",
    "        tags = tags_section.find_all('a', {'href': re.compile(r'/anime/tags/.*')})\n",
    "        tags = [tag.text.replace('\\n', ' ').strip() for tag in tags]\n",
    "    else:\n",
    "        tags = None\n",
    "    \n",
    "    cw_section = soup.find('div', {'class':'tags tags--plain'})\n",
    "    if cw_section:\n",
    "        content_warnings = [cw.text.replace('\\n', ' ').replace(',', '').strip() for cw in cw_section.find_all('li')]\n",
    "    else:\n",
    "        content_warnings = None\n",
    "        \n",
    "    synopsis = soup.find('p').text\n",
    "    url = soup.find('link', {'href': re.compile(r'https://www.anime-planet.com/anime/')})['href']\n",
    "    \n",
    "    return (title, num_eps, studio, start_end_years, season_year, rating, synopsis, tags, content_warnings, url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8ae97575-93d9-429e-8734-00a80b31b8a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "with Pool(14) as p:\n",
    "    list_of_tups = list(p.map(parseInfo, df['html_text']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4eb23429-d47b-4164-be65-79f9a046bb92",
   "metadata": {},
   "outputs": [],
   "source": [
    "anime = pd.DataFrame(list_of_tups, columns=['title', 'num_eps', 'studio', 'start_end_years', 'season_year', 'rating', \n",
    "                                            'synopsis', 'tags', 'content_warnings', 'url'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ae5fd7c6-15f7-4257-95cf-73864914c6a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "anime.to_csv('../data/anime_raw.csv.xz', index=False)\n",
    "anime.to_pickle('../data/anime_raw.pkl.xz')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
