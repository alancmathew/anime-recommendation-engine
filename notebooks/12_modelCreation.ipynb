{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e38bcda-3ff5-429a-ad11-44b281d7ebbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy as sp\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "from multiprocessing import Pool\n",
    "import warnings\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4f9de94-a4e8-4c0b-90b9-4f94436c8a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "tqdm.pandas()\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33f313b1-8e4a-4782-bbb3-c4378158013a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunker(seq, size):\n",
    "    return (seq[pos:pos + size] for pos in range(0, len(seq), size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0fba32d-a882-4a04-8854-f633acbd3dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parallelize(groups, func):\n",
    "    num_workers = 16\n",
    "    with Pool(num_workers) as p:\n",
    "        return pd.concat(p.map(func, [group for name, group in groups])).sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "791015eb-8956-4dad-98a5-f7c42db7ebb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle('../data/train.pkl.xz')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f91dfc1c-8135-4011-805b-52491af59e45",
   "metadata": {},
   "source": [
    "validate_full = pd.read_pickle('../data/validate.pkl.xz')\n",
    "\n",
    "keeper_mask = pd.DataFrame(np.random.uniform(size=validate_full.shape), \n",
    "                           index=validate_full.index, \n",
    "                           columns=validate_full.columns).applymap(lambda x: x > 0.75)\n",
    "\n",
    "validate_masked = validate_full.mask(keeper_mask)\n",
    "\n",
    "validate_actual = validate_full.mask(~keeper_mask)\n",
    "\n",
    "validate_masked.to_pickle('../data/validate_masked.pkl.xz')\n",
    "validate_actual.to_pickle('../data/validate_actual.pkl.xz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5f16796-3c3d-4afb-866d-70518e3a1f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "validate_masked = pd.read_pickle('../data/validate_masked.pkl.xz')\n",
    "validate_actual = pd.read_pickle('../data/validate_actual.pkl.xz')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b0041b4-0266-4d56-8d97-a75904f02999",
   "metadata": {},
   "source": [
    "df = df.fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "664ddd24-afd7-442e-8376-a5a2ab232b8c",
   "metadata": {},
   "source": [
    "sparse = sp.sparse.csr_matrix(df.values, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b7095ec-9a0a-424e-bc08-99061ebc7f98",
   "metadata": {},
   "source": [
    "def similarity_calculator(data):\n",
    "    return pd.DataFrame(cosine_similarity(sparse, data), index=df.index, columns=data.index).astype(np.float16)\n",
    "\n",
    "num_workers = 15\n",
    "chunksize = int(validate_masked.shape[0]/num_workers)+1\n",
    "chunks = chunker(validate_masked.fillna(0), chunksize)\n",
    "with Pool(num_workers) as p:\n",
    "    similarity_matrix = pd.concat(p.map(similarity_calculator, chunks), axis=1)\n",
    "    \n",
    "del chunks\n",
    "\n",
    "similarity_matrix.to_pickle('../data/similarity_matrix.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06a1868b-6100-483b-96a2-1bab38672836",
   "metadata": {},
   "source": [
    "def n_similar_users(column, n=50):\n",
    "    return pd.Series(column.sort_values(ascending=False).head(n).index, name=column.name)\n",
    "\n",
    "with Pool(15) as p:\n",
    "    most_similar_users = pd.concat(p.map(n_similar_users, (tup[1] for tup in similarity_matrix.items())), axis=1)\n",
    "\n",
    "most_similar_users.to_pickle('../data/most_similar_users.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26a24739-a19b-44f0-a6fd-68b3feca3aa8",
   "metadata": {},
   "source": [
    "df = df.replace(0, np.NaN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7bcc039-f41a-4346-9db9-33177f76572a",
   "metadata": {},
   "outputs": [],
   "source": [
    "most_similar_users = pd.read_pickle('../data/most_similar_users.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f253ea7d-59c8-40bf-baf9-001a49292515",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_recommendations(username):\n",
    "    sim_users_data = df.loc[most_similar_users[username].values]\n",
    "\n",
    "    # sim_users_data = sim_users_data.loc[:,sim_users_data.notnull().any(axis=0)]\n",
    "\n",
    "    watch_data = validate_masked.loc[username]\n",
    "\n",
    "    user_watched = watch_data.loc[watch_data.notnull()].index\n",
    "\n",
    "    suggestables = set(sim_users_data.columns).difference(user_watched)\n",
    "\n",
    "    sim_users_data = sim_users_data[suggestables].head(50)\n",
    "\n",
    "#     priors = df[sim_users_data.columns].mean()\n",
    "\n",
    "#     sim_users_data = pd.concat([pd.DataFrame(priors, columns=['average']).T, sim_users_data], axis=0)\n",
    "\n",
    "#     prior_weight = 1.0\n",
    "#     incremental_base = 1.01\n",
    "#     user_weights = [prior_weight] + [incremental_base**x for x in range(sim_users_data.shape[0]-1, 0, -1)]\n",
    "\n",
    "#     weighted_sum = sim_users_data.mul(user_weights, axis=0).sum()\n",
    "\n",
    "#     anime_weights = sim_users_data.notnull().astype('int').mul(user_weights, axis=0).sum()\n",
    "\n",
    "    # pred_data = (weighted_sum / anime_weights).sort_values(ascending=False)\n",
    "    \n",
    "#     incremental_base = 1.00\n",
    "#     user_weights = [incremental_base**x for x in range(sim_users_data.shape[0], 0, -1)]\n",
    "    \n",
    "#     weighted_sum = sim_users_data.mul(user_weights, axis=0).sum()\n",
    "\n",
    "#     anime_weights = sim_users_data.notnull().astype('int').mul(user_weights, axis=0).sum()\n",
    "\n",
    "#     pred_data = (weighted_sum / anime_weights).sort_values(ascending=False)\n",
    "    \n",
    "    pred_data = sim_users_data.mean(axis=0).sort_values(ascending=False)\n",
    "    \n",
    "    return pred_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f99aef0a-791b-417e-a6f8-1369747452c8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "data = validate_masked.index\n",
    "with Pool(15) as p:\n",
    "    validate_pred = pd.DataFrame(p.map(get_recommendations, data.tolist()), index=data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cf21c79-858c-41fd-bdc9-6bf0281696d1",
   "metadata": {},
   "source": [
    "validate_pred.to_pickle('../data/validate_pred.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba4f8628-6cca-46ab-b8f2-fe0b1ac08328",
   "metadata": {},
   "source": [
    "%%bash\n",
    "\n",
    "cd ../data\n",
    "\n",
    "rm validate_pred.pkl.xz\n",
    "xz -vT14 validate_pred.pkl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d2257ac-fb69-4d76-9e77-a2cd3de77b07",
   "metadata": {},
   "source": [
    "validate_pred = pd.read_pickle('../data/validate_pred.pkl.xz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62bbf7fa-6f6e-45b2-b7c2-d7637c117743",
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse = np.sqrt(((validate_pred - validate_actual)**2).mean(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85745dac-e166-434c-80da-5bd7dde62a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e256c3b-8481-4a51-983b-03a6eb96e890",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fcf3f81-8822-44d4-aa3e-1e00d15f3d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Recommender():\n",
    "    def __init__(self):\n",
    "        self.df = pd.read_pickle('../data/train.pkl.xz').fillna(0)\n",
    "        self.sparse = sp.sparse.csr_matrix(self.df.values, dtype=np.float32)\n",
    "        \n",
    "    def similarity_calculator(self, data):\n",
    "        return pd.DataFrame(cosine_similarity(self.sparse, data), index=self.df.index, columns=data.index).astype(np.float16)\n",
    "    \n",
    "    def n_similar_users(self, column, n=50):\n",
    "        return pd.Series(column.sort_values(ascending=False).head(n).index, name=column.name)\n",
    "\n",
    "    def fit(self):\n",
    "        self.X_masked = pd.read_pickle('../data/validate_masked.pkl.xz')\n",
    "        self.X_actual = pd.read_pickle('../data/validate_actual.pkl.xz')\n",
    "        \n",
    "        print('starting similarity matrix...')\n",
    "        num_workers = 15\n",
    "        chunksize = int(self.X_masked.shape[0]/num_workers)+1\n",
    "        chunks = chunker(self.X_masked.fillna(0), chunksize)\n",
    "        with Pool(num_workers) as p:\n",
    "            self.similarity_matrix = pd.concat(p.map(self.similarity_calculator, chunks), axis=1)\n",
    "\n",
    "        del chunks\n",
    "        \n",
    "        print('completed similarity matrix...')\n",
    "        \n",
    "        print('starting most similar users...')\n",
    "        with Pool(15) as p:\n",
    "            self.most_similar_users = pd.concat(p.map(self.n_similar_users, \n",
    "                                                      (tup[1] for tup in self.similarity_matrix.items())), axis=1)\n",
    "           \n",
    "        print('completed most similar users...')\n",
    "        self.df = self.df.replace(0, np.NaN)\n",
    "        self.X_pred = pd.DataFrame(index=self.X_masked.index, columns=self.X_masked.columns)\n",
    "            \n",
    "    def get_recommendations(self, username):\n",
    "        sim_users_data = self.df.loc[self.most_similar_users[username].values]\n",
    "\n",
    "        # sim_users_data = sim_users_data.loc[:,sim_users_data.notnull().any(axis=0)]\n",
    "\n",
    "        watch_data = self.X_masked.loc[username]\n",
    "\n",
    "        user_watched = watch_data.loc[watch_data.notnull()].index\n",
    "\n",
    "        suggestables = set(sim_users_data.columns).difference(user_watched)\n",
    "\n",
    "        sim_users_data = sim_users_data[suggestables].head(50)\n",
    "\n",
    "    #     priors = df[sim_users_data.columns].mean()\n",
    "\n",
    "    #     sim_users_data = pd.concat([pd.DataFrame(priors, columns=['average']).T, sim_users_data], axis=0)\n",
    "\n",
    "    #     prior_weight = 1.0\n",
    "    #     incremental_base = 1.01\n",
    "    #     user_weights = [prior_weight] + [incremental_base**x for x in range(sim_users_data.shape[0]-1, 0, -1)]\n",
    "\n",
    "    #     weighted_sum = sim_users_data.mul(user_weights, axis=0).sum()\n",
    "\n",
    "    #     anime_weights = sim_users_data.notnull().astype('int').mul(user_weights, axis=0).sum()\n",
    "\n",
    "        # pred_data = (weighted_sum / anime_weights).sort_values(ascending=False)\n",
    "\n",
    "        incremental_base = 1.10\n",
    "        user_weights = [incremental_base**x for x in range(sim_users_data.shape[0], 0, -1)]\n",
    "\n",
    "        weighted_sum = sim_users_data.mul(user_weights, axis=0).sum()\n",
    "\n",
    "        anime_weights = sim_users_data.notnull().astype('int').mul(user_weights, axis=0).sum()\n",
    "\n",
    "        self.X_pred.loc[username] = (weighted_sum / anime_weights).sort_values(ascending=False)\n",
    "\n",
    "    #     pred_data = sim_users_data.mean(axis=0).sort_values(ascending=False)\n",
    "\n",
    "        return self.X_pred.loc[username]\n",
    "    \n",
    "    def predict(self, username=None):\n",
    "        if username:\n",
    "            return self.get_recommendations(username)\n",
    "        \n",
    "        else:\n",
    "            with Pool(15) as p:\n",
    "                self.X_pred = pd.DataFrame(p.map(self.get_recommendations, self.X_masked.index.tolist()), index=self.X_masked.index)\n",
    "\n",
    "            return self.X_pred\n",
    "    \n",
    "    \n",
    "    def score(self, username=None):\n",
    "        if username:\n",
    "            return np.sqrt(np.mean((self.X_pred.loc[username] - self.X_actual.loc[username])**2))\n",
    "        \n",
    "        else:\n",
    "            return np.sqrt(((self.X_pred - self.X_actual)**2).mean(axis=1)).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61d6bd46-2c40-442a-bdb8-135309dde65d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Recommender()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b681cf8-84d9-4698-9250-e8d2d6e640ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5f966fe-191a-4db4-ab2a-0f96c9f4990c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.most_similar_users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac185a58-10d0-4c25-822b-65ef3b608fd0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class User:\n",
    "    def __init__(self, watch_data, true_data):\n",
    "        self.username = watch_data.name\n",
    "        self.watch_data = watch_data\n",
    "        self.similar_users = None\n",
    "        self.true_data = true_data\n",
    "        \n",
    "    def get_similar_users(self, min_common=10, sortby='cosine_sim', asc=False, num=50):\n",
    "        # username = userdata.name if username is None else username\n",
    "        # userdata = df.loc[username] if userdata is None else userdata\n",
    "\n",
    "#         common_booled = np.bitwise_and(df == 0, self.watch_data == 0)\n",
    "#         num_common = common_booled.sum(axis=1)\n",
    "\n",
    "#         if sortby == 'corr':\n",
    "#             tmp = df.T\n",
    "#             res = tmp.corrwith(self.watch_data)\n",
    "\n",
    "#         elif sortby == 'dist':\n",
    "#             tmp = df.fillna(0)\n",
    "\n",
    "#             dist = np.sum(tmp.subtract(tmp.loc[self.username], axis=1) ** 2, axis=1)\n",
    "#             dist = dist / num_common\n",
    "#             res = dist.loc[dist != 0]\n",
    "\n",
    "#         elif sortby == 'cosine_sim':\n",
    "        tmp = df.fillna(0)\n",
    "        sparse = sp.sparse.csr_matrix(tmp.values, dtype=np.float32)\n",
    "        res = cosine_similarity(sparse, pd.DataFrame([validate.iloc[0]]).fillna(0))\n",
    "\n",
    "        res = pd.Series(res.flatten(), \n",
    "                        index=df.index).drop(self.username, \n",
    "                                             errors='ignore').sort_values(ascending=False)\n",
    "\n",
    "        data = pd.DataFrame({sortby: res, 'num_common': num_common})\n",
    "        data = data.query(f'username != \"{self.username}\" and num_common >= {min_common}')\n",
    "        data = data.sort_values(sortby, ascending=asc).head(num)\n",
    "        \n",
    "        return data.index\n",
    "    \n",
    "    def get_recommendations(self, num=10, prior_weight=1.0, incremental_base=1.01):\n",
    "        \n",
    "        if self.similar_users is None:\n",
    "            self.similar_users = self.get_similar_users()\n",
    "            \n",
    "        sim_users_data = df.loc[self.similar_users]\n",
    "        sim_users_data = sim_users_data.loc[:,sim_users_data.notnull().any(axis=0)]\n",
    "        user_watched = self.watch_data.loc[self.watch_data.notnull()].index\n",
    "        diff = set(sim_users_data.columns).difference(user_watched)\n",
    "        sim_users_data = sim_users_data[diff].head(num)\n",
    "    \n",
    "        priors = df[sim_users_data.columns].mean()\n",
    "        sim_users_data = pd.concat([pd.DataFrame(priors, columns=['average']).T, sim_users_data], axis=0)\n",
    "        user_weights = [prior_weight] + [incremental_base**x for x in range(sim_users_data.shape[0]-1, 0, -1)]\n",
    "        weighted_sum = sim_users_data.mul(user_weights, axis=0).sum()\n",
    "        anime_weights = sim_users_data.notnull().astype('int').mul(user_weights, axis=0).sum()\n",
    "        self.pred_data = (weighted_sum / anime_weights).sort_values(ascending=False)\n",
    "        \n",
    "        # self.recs = sim_users_data.mean().sort_values(ascending=False)\n",
    "        \n",
    "        return self.pred_data\n",
    "    \n",
    "    def get_rmse(self):\n",
    "        true_data = self.true_data\n",
    "        pred_data = self.pred_data\n",
    "        \n",
    "        true_data = true_data[true_data.notnull()]\n",
    "        watched_intersection = set(true_data.index).intersection(pred_data.index)\n",
    "        true_ratings = true_data[watched_intersection]\n",
    "        pred_ratings = pred_data[watched_intersection]\n",
    "        return np.sqrt(np.mean((true_ratings - pred_ratings)**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a61ba0e1-68e6-4619-b9cc-efe9f726470f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def evaluate_model(idx):\n",
    "    user = User(watch_data=validate.iloc[idx], true_data=validate_true.iloc[idx])\n",
    "    _ = user.get_recommendations()\n",
    "    return user.get_rmse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25d95c2f-7fe7-47a6-bb2f-6e32def65920",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with Pool(16) as p:\n",
    "    rmses = pd.Series(p.map(evaluate_model, range(0, 16)), index=range(0, 16))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04a7aca4-b0e9-4c03-995f-397acc97715e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rmses.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cc65908-326e-41e0-aab4-29fd0d6b04f8",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb0a8f59-84b4-4547-a3b3-4d99c7a08bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_similar_users(username=None, userdata=None, df=df, min_common=10, sortby='cosine_sim', asc=False, num_sim_users=50):    \n",
    "    username = userdata.name if username is None else username\n",
    "    userdata = df.loc[username] if userdata is None else userdata\n",
    "    \n",
    "    common_booled = np.bitwise_and(df.drop(username, axis=0, errors='ignore').notnull(), userdata.notnull())\n",
    "    num_common = common_booled.sum(axis=1)\n",
    "    \n",
    "    if sortby == 'corr':\n",
    "        tmp = df.T\n",
    "        res = tmp.corrwith(userdata)\n",
    "    \n",
    "    elif sortby == 'dist':\n",
    "        tmp = df.fillna(0)\n",
    "\n",
    "        dist = np.sum(tmp.subtract(tmp.loc[username], axis=1) ** 2, axis=1)\n",
    "        dist = dist / num_common\n",
    "        res = dist.loc[dist != 0]\n",
    "        \n",
    "    elif sortby == 'cosine_sim':\n",
    "        tmp = df.fillna(0)\n",
    "        sparse = sp.sparse.csr_matrix(tmp.values, dtype=np.float32)\n",
    "        res = cosine_similarity(sparse, np.array(userdata.fillna(0)).reshape(1, -1))\n",
    "\n",
    "        res = pd.Series(res.flatten(), index=df.index).drop(username, errors='ignore').sort_values(ascending=False)\n",
    "    \n",
    "    elif sortby == 'num_common':\n",
    "        res = []\n",
    "    \n",
    "    data = pd.DataFrame({sortby: res, 'num_common': num_common})\n",
    "    data = data.query(f'username != \"{username}\" and num_common >= {min_common}')\n",
    "    data = data.sort_values(sortby, ascending=asc).head(num_sim_users)\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5793dd5b-000e-4da7-ad22-026fbe671991",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_recommendations(username=None, userdata=None, df=df, min_common=10, sortby='cosine_sim', asc=False, num_sim_users=50):\n",
    "    username = userdata.name if username is None else username\n",
    "    userdata = df.loc[username] if userdata is None else userdata\n",
    "    \n",
    "    sim_users = get_similar_users(username=username, userdata=userdata, df=df, min_common=min_common, \n",
    "                                  sortby=sortby, asc=asc, num_sim_users=num_sim_users)\n",
    "    sim_users_data = df.loc[sim_users.index]\n",
    "    sim_users_data = sim_users_data.loc[:,sim_users_data.notnull().any(axis=0)]\n",
    "    user_watched = userdata.loc[userdata.notnull()].index\n",
    "    diff = set(sim_users_data.columns).difference(user_watched)\n",
    "    sim_users_data = sim_users_data[diff]\n",
    "\n",
    "    # recs = sim_users_data.mean().sort_values(ascending=False)\n",
    "    \n",
    "    \n",
    "    priors = df[sim_users_data.columns].mean()\n",
    "    sim_users_data = pd.concat([pd.DataFrame(priors, columns=['average']).T, sim_users_data], axis=0)\n",
    "    user_weights = [1.5] + [1.01**x for x in range(sim_users_data.shape[0]-1, 0, -1)]\n",
    "    weighted_sum = sim_users_data.mul(user_weights, axis=0).sum()\n",
    "    anime_weights = sim_users_data.notnull().astype('int').mul(user_weights, axis=0).sum()\n",
    "    recs = (weighted_sum / anime_weights).sort_values(ascending=False)\n",
    "    \n",
    "    return recs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67adc79e-0e7a-4412-90a2-97921bc77a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rmse(pred_data, true_data):\n",
    "    true_data = true_data[true_data.notnull()]\n",
    "    watched_intersection = set(true_data.index).intersection(pred_data.index)\n",
    "    true_ratings = true_data[watched_intersection]\n",
    "    pred_ratings = pred_data[watched_intersection]\n",
    "    return np.sqrt(np.mean((true_ratings - pred_ratings)**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53d51487-8550-4ad4-9091-9d678e381dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_userdata = get_recommendations(userdata=validate.iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dcac704-6e3e-48fc-91b2-d23f2133cf13",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_rmse(pred_userdata, validate_true.iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b120ced-a8ea-4784-82c0-5aa3d8f3c9f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_rmse = 0\n",
    "for idx in tqdm(range(10)):\n",
    "    userdata = validate.iloc[idx]\n",
    "    pred_userdata = get_recommendations(userdata=userdata, num_sim_users=50, sortby='corr')\n",
    "    true_userdata = validate_true.iloc[idx]\n",
    "    rmse = get_rmse(pred_userdata, true_userdata)\n",
    "    total_rmse += rmse if not(pd.isna(rmse)) else 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "905900dc-8c5e-4b4c-8de7-95fc90165cef",
   "metadata": {},
   "source": [
    "50 users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76d1cb12-ae3b-449e-8195-090aa19eca08",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_rmse / 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34c55101-034d-4454-b7d4-b4434a731303",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 3\n",
    "userdata = validate.iloc[idx]\n",
    "pred_userdata = get_recommendation(userdata=userdata, num_recs=100, num_users=5)\n",
    "true_userdata = validate_true.iloc[idx]\n",
    "get_rmse(pred_userdata, true_userdata)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
