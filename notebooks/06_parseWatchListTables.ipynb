{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a6807ed4-3912-4121-8af5-486652ec8bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import sqlalchemy as sql\n",
    "from tqdm import tqdm\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from io import StringIO\n",
    "from urllib.parse import quote\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import threading\n",
    "from multiprocessing import Pool\n",
    "import time\n",
    "import random\n",
    "import re\n",
    "import itertools\n",
    "import zlib\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a2ce98e-aefe-4a72-beaa-0be04c86f1f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../tools/credentials.json') as file:\n",
    "    credentials = json.load(file)\n",
    "    \n",
    "username = credentials[\"dblogin\"][\"username\"]\n",
    "password = credentials[\"dblogin\"][\"password\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac5015bd-e350-494c-88ef-0a96391448f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "db_string = f\"postgresql://{username}:{password}@192.168.0.3:5432/animeplanet\"\n",
    "db = sql.create_engine(db_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c754a18b-6d5c-454e-92c7-bdeb2e27f82c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunker(seq, size):\n",
    "    return (seq[pos:pos + size] for pos in range(0, len(seq), size))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed72026b-6172-400b-b3f3-0471c53d9f8c",
   "metadata": {},
   "source": [
    "### Parse User Watch List Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c0809d7-1d33-4dab-8634-623de8d761d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "        SELECT origin_url\n",
    "        FROM watch_list;\n",
    "        \"\"\"\n",
    "\n",
    "completed_set = set(pd.read_sql(sql.text(query), db)['origin_url'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d829cc1d-272d-495a-a702-7e3c42c9014a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_rows():\n",
    "    query = f\"\"\"\n",
    "            SELECT COUNT(*)\n",
    "            FROM web_scrape\n",
    "            WHERE html_text IS NOT NULL\n",
    "            AND url LIKE 'https://www.anime-planet.com/users/%/anime?sort=title&mylist_view=list%';\n",
    "            \"\"\"\n",
    "    \n",
    "    return pd.read_sql(sql.text(query), db)['count'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3546b70-c636-4bf5-a8cd-0b5bbfdcfcde",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def read_sql_chunks(chunksize):\n",
    "\n",
    "    num_rows = count_rows()\n",
    "    \n",
    "    for offset in range(0, num_rows, chunksize):\n",
    "        query = f\"\"\"\n",
    "                SELECT *\n",
    "                FROM web_scrape\n",
    "                WHERE html_text IS NOT NULL\n",
    "                AND url LIKE 'https://www.anime-planet.com/users/%/anime?sort=title&mylist_view=list%'\n",
    "                LIMIT {chunksize} OFFSET {offset};\n",
    "                \"\"\"\n",
    "            \n",
    "        chunk = pd.read_sql(sql.text(query), db)\n",
    "        \n",
    "        yield chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53b0723b-6a97-46cd-8707-155e9590615a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compressText(text):\n",
    "    return zlib.compress(bytes(text, 'utf-8') if type(text) == str else text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9b66de4-f3d2-41e9-85fd-31735590eb38",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decompressText(text):\n",
    "    return str(zlib.decompress(text), 'utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26ac7cc0-1055-4187-897f-be3ee95daff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compressData(data):\n",
    "    data = data.loc[~data['url'].isin(completed_set)].copy(deep=True)\n",
    "    \n",
    "    if data.shape[0] == 0:\n",
    "        return pd.DataFrame(columns=['url', 'comp_html_bytes'])\n",
    "    \n",
    "    data['comp_html_bytes'] = data['html_text'].apply(compressText)\n",
    "    \n",
    "    del data['html_text']\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2146bc0-2744-43db-b9b6-2706fa41376b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parallelize(data, func):\n",
    "    data_split = np.array_split(data, 15)\n",
    "    \n",
    "    with Pool(15) as p:\n",
    "        data = pd.concat([*p.map(func, data_split)], ignore_index=True)\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc34876f-3359-4cb8-9e37-951c42ce74b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def saveData(df):\n",
    "    with db.connect() as con:\n",
    "        df.to_sql('watch_list', con, if_exists='append', index=False, method='multi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a47a9485-94a3-4e2d-aece-539996866f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parseTable(url_html_tup):\n",
    "    url, html_text = url_html_tup\n",
    "    try:\n",
    "        soup = BeautifulSoup(html_text, 'html.parser')\n",
    "        table = soup.find('table')\n",
    "        df = pd.read_html(StringIO(str(table)))[0]\n",
    "        df.columns = ['title', 'type', 'year', 'avg', 'status', 'eps', 'times_watched', 'rating']\n",
    "        df['times_watched'] = df['times_watched'].str.extract(r'([0-9]*)', expand=False).astype('float')\n",
    "        df['anime_url'] = [np.where(tag.has_attr('href'), \n",
    "                           'https://www.anime-planet.com' + tag.get('href'), \n",
    "                           'no link') for tag in [td.find('a') for td in table.find_all('td', attrs={'class':'tableTitle'})]]\n",
    "        df['anime_url'] = df['anime_url'].astype('string')\n",
    "        df['username'] = str(re.findall(r'/users/([A-Za-z0-9]*)/', url)[0])\n",
    "        df['origin_url'] = url\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    except:\n",
    "        return pd.DataFrame(columns=['title', 'type', 'year', 'avg', 'status', \n",
    "                                     'eps', 'times_watched', 'rating', 'anime_url', 'username', 'origin_url'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c44de8f5-c72c-4fee-a616-d5f7dd7b74d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunksize = 1000\n",
    "num_rows = count_rows()\n",
    "sql_chunks = read_sql_chunks(chunksize)\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=1) as executor:\n",
    "    for idx, chunk in enumerate(tqdm(sql_chunks, total=int(num_rows/chunksize)+1)):\n",
    "        chunk = chunk.loc[~chunk['url'].isin(completed_set)].copy(deep=True)\n",
    "        list_of_tups = [tuple(r) for r in chunk.to_numpy()]\n",
    "        with Pool(14) as p:\n",
    "            if len(list_of_tups) == 0:\n",
    "                chunk = pd.DataFrame(columns=['title', 'type', 'year', 'avg', 'status', \n",
    "                                              'eps', 'times_watched', 'rating', 'anime_url', 'username', 'origin_url'])\n",
    "            else:\n",
    "                chunk = pd.concat([*p.map(parseTable, list_of_tups)], ignore_index=True)\n",
    "        if idx != 0:\n",
    "            _ = save_thread.result()\n",
    "        save_thread = executor.submit(saveData, chunk)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
